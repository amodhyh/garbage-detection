{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Digital Image Processing EC9570\n",
    "## Garbage Classification project\n",
    "2021/E/045\n",
    "2021/E/179"
   ],
   "id": "136def4a366dfbc0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Imports & Setup",
   "id": "4cdcd80f71b689a1"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-13T03:29:02.738433Z",
     "start_time": "2025-09-13T03:29:01.062297Z"
    }
   },
   "source": [
    "import random\n",
    "!pip install -r requirements.txt"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from -r requirements.txt (line 1)) (2.8.0)\n",
      "Requirement already satisfied: torchvision in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from -r requirements.txt (line 2)) (0.23.0)\n",
      "Requirement already satisfied: numpy in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from -r requirements.txt (line 3)) (2.2.6)\n",
      "Requirement already satisfied: matplotlib in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from -r requirements.txt (line 4)) (3.10.5)\n",
      "Requirement already satisfied: scikit-learn in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from -r requirements.txt (line 5)) (1.7.1)\n",
      "Requirement already satisfied: opencv-python in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from -r requirements.txt (line 6)) (4.12.0.88)\n",
      "Requirement already satisfied: filelock in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (1.14.0)\n",
      "Requirement already satisfied: networkx in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (3.5)\n",
      "Requirement already satisfied: jinja2 in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (2025.7.0)\n",
      "Requirement already satisfied: setuptools in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (80.9.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from torchvision->-r requirements.txt (line 2)) (11.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (4.59.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (2.9.0.post0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 4)) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from jinja2->torch->-r requirements.txt (line 1)) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T03:29:02.755864Z",
     "start_time": "2025-09-13T03:29:02.753241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ],
   "id": "8e97b38634bdf175",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Inspecting the Dataset",
   "id": "b536893994045b05"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T03:29:02.782767Z",
     "start_time": "2025-09-13T03:29:02.776602Z"
    }
   },
   "cell_type": "code",
   "source": "data_dir='./raw/'",
   "id": "6d7371dd4c70c5f7",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T03:29:02.914524Z",
     "start_time": "2025-09-13T03:29:02.910049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "def class_count(directory):\n",
    "    image_directories=[]\n",
    "    for folder in os.listdir(directory):\n",
    "        sub_folder_path=os.path.join(data_dir,folder)\n",
    "        image_directories.append(sub_folder_path)\n",
    "        print(f\"{folder} - {len(os.listdir(sub_folder_path))}\")\n"
   ],
   "id": "7a47a8696ae35662",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Data Augmentation Functions",
   "id": "648fd7c15cd7bf02"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T03:29:02.930297Z",
     "start_time": "2025-09-13T03:29:02.926222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy\n",
    "import cv2\n",
    "def rotate(image):\n",
    "\n",
    "    angle=random.randint(-30,30)\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    rot_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated_image = cv2.warpAffine(image, rot_matrix, (w, h))\n",
    "\n",
    "    return rotated_image\n"
   ],
   "id": "233ad8ef4b43293b",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Flip",
   "id": "cae731cf72a7af9e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T03:29:02.985004Z",
     "start_time": "2025-09-13T03:29:02.945404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def flip(image):\n",
    "    flip_code=random.choice([0,1,-1])\n",
    "    flipped_image = cv2.flip(image, flip_code)\n",
    "    return flipped_image"
   ],
   "id": "79a328bba854f949",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Gaussian Blur",
   "id": "8436f55aa2436ab6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T03:29:03.030023Z",
     "start_time": "2025-09-13T03:29:03.010507Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Kernel size must be an odd number\n",
    "def gaussian_blur(image):\n",
    "    ksize = random.choice([3, 5, 7])\n",
    "    blurred_image = cv2.GaussianBlur(image, (ksize, ksize), 0)\n",
    "    return blurred_image"
   ],
   "id": "784ea2d1a4afff37",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Random Erasing",
   "id": "df1c122f55b9bf5f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T03:29:03.076356Z",
     "start_time": "2025-09-13T03:29:03.068825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Randomly selects a rectangle region in an image and erases its pixels.\n",
    "def random_erasing(image):\n",
    "    erased_image = image.copy()\n",
    "    (h, w) = image.shape[:2]\n",
    "    # Define a random rectangle area to erase\n",
    "    erase_h = random.randint(int(h * 0.1), int(h * 0.3))\n",
    "    erase_w = random.randint(int(w * 0.1), int(w * 0.3))\n",
    "    x1 = random.randint(0, w - erase_w)\n",
    "    y1 = random.randint(0, h - erase_h)\n",
    "    # Set the area to black\n",
    "    erased_image[y1:y1 + erase_h, x1:x1 + erase_w] = (0, 0, 0)\n",
    "    return erased_image\n"
   ],
   "id": "96aefe1fa9b136fc",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Histogram Equalization",
   "id": "798245f80fc38d89"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T03:29:03.119412Z",
     "start_time": "2025-09-13T03:29:03.091796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def histogram_equalization(image):\n",
    "    # Convert to YCrCb color space\n",
    "    ycrcb = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "    # Equalize the histogram of the Y channel\n",
    "    ycrcb[:, :, 0] = cv2.equalizeHist(ycrcb[:, :, 0])\n",
    "    # Convert back to BGR\n",
    "    equalized_img = cv2.cvtColor(ycrcb, cv2.COLOR_YCrCb2BGR)\n",
    "    return equalized_img\n"
   ],
   "id": "9579f93d3bb4ddf1",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Normalization",
   "id": "114d3e0aeaff55c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T03:29:03.172810Z",
     "start_time": "2025-09-13T03:29:03.159368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalize(image):\n",
    "    # Convert to float32 and scale to [0, 1]\n",
    "    norm_img = image.astype(np.float32) / 255.0\n",
    "    return norm_img\n"
   ],
   "id": "e1ec2622c636c31f",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Balancing the Dataset",
   "id": "8f6f5fcfa4f65370"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T03:29:21.234023Z",
     "start_time": "2025-09-13T03:29:03.189295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "\n",
    "source_dir = './raw/'\n",
    "output_dir = './processed/'\n",
    "target_size = (256, 256)\n",
    "\n",
    "# List of available augmentation functions\n",
    "augmentations = [rotate, flip, gaussian_blur, random_erasing]\n",
    "\n",
    "# 1. Calculate class sizes and find the target number of images\n",
    "class_counts = {}\n",
    "for folder in os.listdir(source_dir):\n",
    "    folder_path = os.path.join(source_dir, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        class_counts[folder] = len(os.listdir(folder_path))\n",
    "\n",
    "if not class_counts:\n",
    "    print(\"Source directory is empty or contains no subdirectories.\")\n",
    "else:\n",
    "    max_images = max(class_counts.values())\n",
    "    print(f\"Target image count per class: {max_images}\")\n",
    "\n",
    "    # 2. Create output directories and process each class\n",
    "    for class_name, current_count in class_counts.items():\n",
    "        print(f\"Processing class: {class_name}\")\n",
    "\n",
    "        # Create corresponding output directory\n",
    "        output_class_dir = os.path.join(output_dir, class_name)\n",
    "        os.makedirs(output_class_dir, exist_ok=True)\n",
    "\n",
    "        source_class_dir = os.path.join(source_dir, class_name)\n",
    "        image_files = [f for f in os.listdir(source_class_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "        # Copy original images\n",
    "        for filename in image_files:\n",
    "            img_path = os.path.join(source_class_dir, filename)\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is None:\n",
    "                continue\n",
    "            # Apply histogram equalization and normalization\n",
    "            image = histogram_equalization(image)\n",
    "            image = cv2.resize(image, target_size)\n",
    "            # Normalization is typically for model input, not for saving as image\n",
    "            # If you want to save normalized images, convert back to uint8\n",
    "            # image = normalize(image)\n",
    "            # image = (image * 255).astype(np.uint8)\n",
    "            save_path = os.path.join(output_class_dir, filename)\n",
    "            cv2.imwrite(save_path, image)\n",
    "\n",
    "        # 3. Generate new images if needed\n",
    "        num_to_generate = max_images - current_count\n",
    "        print(f\"Generating {num_to_generate} new images for {class_name}...\")\n",
    "\n",
    "        for i in range(num_to_generate):\n",
    "            # Pick a random original image to augment\n",
    "            random_image_name = random.choice(image_files)\n",
    "            image_path = os.path.join(source_class_dir, random_image_name)\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            if image is None:\n",
    "                continue\n",
    "\n",
    "            # Apply a random number of augmentations\n",
    "            num_aug_to_apply = random.randint(1, len(augmentations))\n",
    "            augs_to_apply = random.sample(augmentations, num_aug_to_apply)\n",
    "\n",
    "            augmented_image = image\n",
    "            for aug_func in augs_to_apply:\n",
    "                augmented_image = aug_func(augmented_image)\n",
    "\n",
    "            # Apply histogram equalization and normalization\n",
    "            augmented_image = histogram_equalization(augmented_image)\n",
    "            augmented_image = cv2.resize(augmented_image, target_size)\n",
    "            # Normalization is typically for model input, not for saving as image\n",
    "            # augmented_image = normalize(augmented_image)\n",
    "            # augmented_image = (augmented_image * 255).astype(np.uint8)\n",
    "\n",
    "            # Save the new image\n",
    "            base_filename, file_ext = os.path.splitext(random_image_name)\n",
    "            new_filename = f\"{base_filename}_aug_{i}{file_ext}\"\n",
    "            save_path = os.path.join(output_class_dir, new_filename)\n",
    "            cv2.imwrite(save_path, augmented_image)\n",
    "\n",
    "    print(\"\\nDataset balancing complete.\")\n"
   ],
   "id": "3fe8c0a7ace112c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target image count per class: 594\n",
      "Processing class: cardboard\n",
      "Generating 191 new images for cardboard...\n",
      "Processing class: glass\n",
      "Generating 93 new images for glass...\n",
      "Processing class: metal\n",
      "Generating 184 new images for metal...\n",
      "Processing class: paper\n",
      "Generating 0 new images for paper...\n",
      "Processing class: plastic\n",
      "Generating 112 new images for plastic...\n",
      "Processing class: trash\n",
      "Generating 457 new images for trash...\n",
      "\n",
      "Dataset balancing complete.\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T03:29:21.271716Z",
     "start_time": "2025-09-13T03:29:21.265024Z"
    }
   },
   "cell_type": "code",
   "source": "class_count('./processed/')",
   "id": "7d2b688db4e3a0a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardboard - 403\n",
      "glass - 501\n",
      "metal - 410\n",
      "paper - 594\n",
      "plastic - 482\n",
      "trash - 137\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T03:29:21.284925Z",
     "start_time": "2025-09-13T03:29:21.282537Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "cc01909c0737c333",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
