{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Digital Image Processing EC9570\n",
    "## Garbage Classification project\n",
    "2021/E/045\n",
    "2021/E/179"
   ],
   "id": "136def4a366dfbc0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Imports & Setup",
   "id": "4cdcd80f71b689a1"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-13T03:29:02.738433Z",
     "start_time": "2025-09-13T03:29:01.062297Z"
    }
   },
   "source": [
    "import random\n",
    "!pip install -r requirements.txt"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from -r requirements.txt (line 1)) (2.8.0)\n",
      "Requirement already satisfied: torchvision in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from -r requirements.txt (line 2)) (0.23.0)\n",
      "Requirement already satisfied: numpy in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from -r requirements.txt (line 3)) (2.2.6)\n",
      "Requirement already satisfied: matplotlib in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from -r requirements.txt (line 4)) (3.10.5)\n",
      "Requirement already satisfied: scikit-learn in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from -r requirements.txt (line 5)) (1.7.1)\n",
      "Requirement already satisfied: opencv-python in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from -r requirements.txt (line 6)) (4.12.0.88)\n",
      "Requirement already satisfied: filelock in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (1.14.0)\n",
      "Requirement already satisfied: networkx in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (3.5)\n",
      "Requirement already satisfied: jinja2 in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (2025.7.0)\n",
      "Requirement already satisfied: setuptools in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (80.9.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from torchvision->-r requirements.txt (line 2)) (11.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (4.59.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (2.9.0.post0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 4)) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in f:\\uoje\\semester 7\\digital image processing\\project\\.dipproject_venv\\lib\\site-packages (from jinja2->torch->-r requirements.txt (line 1)) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T03:29:02.755864Z",
     "start_time": "2025-09-13T03:29:02.753241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ],
   "id": "8e97b38634bdf175",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Inspecting the Dataset",
   "id": "b536893994045b05"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T03:29:02.782767Z",
     "start_time": "2025-09-13T03:29:02.776602Z"
    }
   },
   "cell_type": "code",
   "source": "data_dir='./raw/'",
   "id": "6d7371dd4c70c5f7",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T03:29:02.914524Z",
     "start_time": "2025-09-13T03:29:02.910049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "def class_count(directory):\n",
    "    image_directories=[]\n",
    "    for folder in os.listdir(directory):\n",
    "        sub_folder_path=os.path.join(data_dir,folder)\n",
    "        image_directories.append(sub_folder_path)\n",
    "        print(f\"{folder} - {len(os.listdir(sub_folder_path))}\")\n"
   ],
   "id": "7a47a8696ae35662",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Data Augmentation Functions",
   "id": "648fd7c15cd7bf02"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Rotation",
   "id": "25e5967e8855f685"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def rotate(image):\n",
    "\n",
    "    angle=random.randint(-30,30)\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    rot_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated_image = cv2.warpAffine(image, rot_matrix, (w, h))\n",
    "\n",
    "    return rotated_image\n"
   ],
   "id": "c77beac9a393c064"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Flip",
   "id": "cae731cf72a7af9e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def flip(image):\n",
    "    flip_code=random.choice([0,1,-1])\n",
    "    flipped_image = cv2.flip(image, flip_code)\n",
    "    return flipped_image"
   ],
   "id": "b771f10d057a917f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Random Erasing",
   "id": "df1c122f55b9bf5f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Randomly selects a rectangle region in an image and erases its pixels.\n",
    "def random_erasing(image):\n",
    "    erased_image = image.copy()\n",
    "    (h, w) = image.shape[:2]\n",
    "    # Define a random rectangle area to erase\n",
    "    erase_h = random.randint(int(h * 0.1), int(h * 0.3))\n",
    "    erase_w = random.randint(int(w * 0.1), int(w * 0.3))\n",
    "    x1 = random.randint(0, w - erase_w)\n",
    "    y1 = random.randint(0, h - erase_h)\n",
    "    # Set the area to black\n",
    "    erased_image[y1:y1 + erase_h, x1:x1 + erase_w] = (0, 0, 0)\n",
    "    return erased_image\n"
   ],
   "id": "f4e5fd0a5d372cad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Balancing the Dataset",
   "id": "8f6f5fcfa4f65370"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T18:23:53.495986Z",
     "start_time": "2025-09-21T18:18:39.372302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "source_dir = './raw/'\n",
    "output_dir = './processed/'\n",
    "\n",
    "# List of available augmentation functions\n",
    "augmentations = [rotate, flip, random_erasing]\n",
    "\n",
    "# 1. Calculate class sizes and find the target number of images\n",
    "class_counts = {}\n",
    "for folder in os.listdir(source_dir):\n",
    "    folder_path = os.path.join(source_dir, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        class_counts[folder] = len(os.listdir(folder_path))\n",
    "\n",
    "if not class_counts:\n",
    "    print(\"Source directory is empty or contains no subdirectories.\")\n",
    "else:\n",
    "    max_images = max(class_counts.values())\n",
    "    print(f\"Target image count per class: {max_images}\")\n",
    "\n",
    "    # 2. Create output directories and process each class\n",
    "    for class_name, current_count in class_counts.items():\n",
    "        print(f\"Processing class: {class_name}\")\n",
    "\n",
    "        # Create corresponding output directory\n",
    "        output_class_dir = os.path.join(output_dir, class_name)\n",
    "        os.makedirs(output_class_dir, exist_ok=True)\n",
    "\n",
    "        source_class_dir = os.path.join(source_dir, class_name)\n",
    "        image_files = [f for f in os.listdir(source_class_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "        # Copy original images\n",
    "        for filename in image_files:\n",
    "            img_path = os.path.join(source_class_dir, filename)\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is None:\n",
    "                continue\n",
    "            save_path = os.path.join(output_class_dir, filename)\n",
    "            cv2.imwrite(save_path, image)\n",
    "\n",
    "        #  Generate new images if needed\n",
    "        num_to_generate = max_images - current_count\n",
    "        print(f\"Generating {num_to_generate} new images for {class_name}...\")\n",
    "\n",
    "        for i in range(num_to_generate):\n",
    "            # Pick a random original image to augment\n",
    "            random_image_name = random.choice(image_files)\n",
    "            image_path = os.path.join(source_class_dir, random_image_name)\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            if image is None:\n",
    "                continue\n",
    "\n",
    "            # Apply a random number of augmentations\n",
    "            num_aug_to_apply = random.randint(1, len(augmentations))\n",
    "            augs_to_apply = random.sample(augmentations, num_aug_to_apply)\n",
    "\n",
    "            augmented_image = image\n",
    "            for aug_func in augs_to_apply:\n",
    "                augmented_image = aug_func(augmented_image)\n",
    "\n",
    "            # Save the new image\n",
    "            base_filename, file_ext = os.path.splitext(random_image_name)\n",
    "            new_filename = f\"{base_filename}_aug_{i}{file_ext}\"\n",
    "            save_path = os.path.join(output_class_dir, new_filename)\n",
    "            cv2.imwrite(save_path, augmented_image)\n",
    "\n",
    "    print(\"\\nDataset balancing complete.\")\n"
   ],
   "id": "cbcd99fbb270c2b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target image count per class: 5325\n",
      "Processing class: battery\n",
      "Generating 4380 new images for battery...\n",
      "Processing class: biological\n",
      "Generating 4340 new images for biological...\n",
      "Processing class: brown-glass\n",
      "Generating 4718 new images for brown-glass...\n",
      "Processing class: cardboard\n",
      "Generating 4434 new images for cardboard...\n",
      "Processing class: clothes\n",
      "Generating 0 new images for clothes...\n",
      "Processing class: green-glass\n",
      "Generating 4696 new images for green-glass...\n",
      "Processing class: metal\n",
      "Generating 4556 new images for metal...\n",
      "Processing class: paper\n",
      "Generating 4275 new images for paper...\n",
      "Processing class: plastic\n",
      "Generating 4460 new images for plastic...\n",
      "Processing class: shoes\n",
      "Generating 3348 new images for shoes...\n",
      "Processing class: trash\n",
      "Generating 4628 new images for trash...\n",
      "Processing class: white-glass\n",
      "Generating 4550 new images for white-glass...\n",
      "\n",
      "Dataset balancing complete.\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Pre-Processing Stratey",
   "id": "8a42a9e65ead20b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "now we have a balanced dataset with each class containing the same number of images. The images have been resized to 128x128 pixels, and various augmentations have been applied to generate new images for classes that initially had fewer samples. Additionally, histogram equalization has been applied to enhance image contrast.\n",
    "1. Resize to 128x128\n",
    "2. Denoise (Gaussian blur)\n",
    "3. Sharpen\n",
    "4. Histogram equalization\n",
    "5. Normalize to [0, 1]"
   ],
   "id": "7137bc39530ca4aa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Resize",
   "id": "37b64394b9898df1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T19:05:53.566858Z",
     "start_time": "2025-09-21T19:05:53.561234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Resize to 128x128\n",
    "def resize(image, size=(128, 128)):\n",
    "    resized_img = cv2.resize(image, size)\n",
    "    return resized_img"
   ],
   "id": "cc47e9136a2ead53",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Denoise",
   "id": "67a1e355a8622f0f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T19:05:54.659555Z",
     "start_time": "2025-09-21T19:05:54.653233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def denoise(image):\n",
    "    h, w = image.shape[:2]\n",
    "    # Kernel size: 1/50th of the smallest dimension, rounded to nearest odd integer\n",
    "    ksize = max(3, min(15, (min(h, w) // 50) | 1))\n",
    "    blurred_image = cv2.GaussianBlur(image, (ksize, ksize), 0)\n",
    "    return blurred_image\n"
   ],
   "id": "6e56bab4caad88aa",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Sharpen",
   "id": "90841a104afbbfb0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T19:05:56.944303Z",
     "start_time": "2025-09-21T19:05:56.939275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sharpen(image):\n",
    "    h, w = image.shape[:2]\n",
    "    # Sharpening strength: scale with image size, but keep reasonable bounds\n",
    "    alpha = min(2.0, max(1.0, min(h, w) / 128))\n",
    "    # Sharpening kernel\n",
    "    kernel = np.array([[0, -1, 0],\n",
    "                       [-1, 4 * alpha + 1, -1],\n",
    "                       [0, -1, 0]])\n",
    "    kernel = kernel / (4 * alpha)\n",
    "    sharpened = cv2.filter2D(image, -1, kernel)\n",
    "    return sharpened\n"
   ],
   "id": "76cc136dd9a442fb",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Histogram Equilization",
   "id": "130889b22824b9cd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T19:05:58.288190Z",
     "start_time": "2025-09-21T19:05:58.207570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def histogram_equalization(image):\n",
    "    # Convert to YCrCb color space\n",
    "    ycrcb = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "    # Equalize the histogram of the Y channel\n",
    "    ycrcb[:, :, 0] = cv2.equalizeHist(ycrcb[:, :, 0])\n",
    "    # Convert back to BGR\n",
    "    equalized_img = cv2.cvtColor(ycrcb, cv2.COLOR_YCrCb2BGR)\n",
    "    return equalized_img"
   ],
   "id": "e611e4831df1e21",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Normalize",
   "id": "8eac254e07a823e6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T19:05:59.167689Z",
     "start_time": "2025-09-21T19:05:59.163169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalize(image):\n",
    "    # Convert to float32 and scale to [0, 1]\n",
    "    norm_img = image.astype(np.float32) / 255.0\n",
    "    return norm_img\n"
   ],
   "id": "7afe8b7e7c571d27",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Pre Processing the image dataset\n",
   "id": "591d4766cc1377dc"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-09-21T19:06:11.085904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "source_dir = './processed/'\n",
    "output_dir = './final/'\n",
    "\n",
    "for directory in os.listdir(source_dir):\n",
    "    source_class_dir = os.path.join(source_dir, directory)\n",
    "    output_class_dir = os.path.join(output_dir, directory)\n",
    "    os.makedirs(output_class_dir, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(source_class_dir):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            img_path = os.path.join(source_class_dir, filename)\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is None:\n",
    "                continue\n",
    "\n",
    "            # Apply preprocessing steps\n",
    "            image = resize(image)\n",
    "            image = denoise(image)\n",
    "            image = sharpen(image)\n",
    "            image = histogram_equalization(image)\n",
    "            image = normalize(image)\n",
    "\n",
    "            # Save the preprocessed image\n",
    "            save_path = os.path.join(output_class_dir, filename)\n",
    "            cv2.imwrite(save_path, (image * 255).astype(np.uint8))\n"
   ],
   "id": "7bfe99659e03d39b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7698dda5bd4b4f86"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
